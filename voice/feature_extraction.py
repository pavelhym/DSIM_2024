# -*- coding: utf-8 -*-
"""FeatureExtraction_DSIM_Project_Monochannelsignal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mt01lGlyuOt2iRwkOVcXooPMWi4kAkEP
"""

import os
import numpy as np
from shutil import copytree
import pandas as pd

from sklearn.model_selection import train_test_split

from librosa import load
from scipy.signal import spectrogram
from librosa.feature import melspectrogram, mfcc, rms, zero_crossing_rate, chroma_stft

from google.colab import drive
drive.mount('/content/gdrive')

copytree('/content/gdrive/MyDrive/DSIM_Project_Monochannelsignal/augmented_audios','augmented_audios')

"""## **Data Preprocessing**"""

def detectEmotion(emotion):

    if(emotion == '01'): return 'Neutral'
    if(emotion == '02'): return 'Calm'
    if(emotion == '03'): return 'Happy'
    if(emotion == '04'): return 'Sad'
    if(emotion == '05'): return 'Angry'
    if(emotion == '06'): return 'Fearful'
    if(emotion == '07'): return 'Disgust'
    else: return 'Surprised'

path = '/content/augmented_audios'

audios = []
for audio in os.listdir(path):
  audio_feature = {
      'filename': audio,
      'label' : detectEmotion(audio.split('-')[2])
    }
  audios.append(audio_feature)
df = pd.DataFrame(audios)

df.head()

"""## **Data Loader**"""

# Placecholder for feature extractor
def identity(input):
    return input

# Data loader
def load_data_csv(feature_extractor=identity, normalize=False):

    files = []
    labels = []
    features = []

    for i,row in enumerate(df.iterrows()):
        f = row[1]['filename']
        files.append(f)

        # Load file and compute the requested features
        signal, sr = load('./augmented_audios/' + f)
        cur_features = feature_extractor(signal, sr)
        features.append(cur_features)

        # Classes
        label = row[1]['label']
        labels.append(label)


    # # X: features, y: labels
    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=1)

    if normalize:
        eps = 0.001
        X_train = np.array(X_train)
        X_test = np.array(X_test)

        for i in range(X_train.shape[0]):
          X_train_mean = X_train[i].mean()
          X_train_std = X_train[i].std()
          X_train[i] = (X_train[i] - X_train_mean + eps)/(X_train_std + eps)
          X_train[i] = [row for row in X_train[i]]

        for i in range(X_test.shape[0]):
          X_test_mean = X_test[i].mean()
          X_test_std = X_test[i].std()
          X_test[i] = (X_test[i] - X_test_mean + eps)/(X_test_std + eps)
          X_test[i] = [row for row in X_test[i]]

    return X_train, X_test, y_train, y_test

"""## **Feature Extractors**

#### **Root Mean Square**
"""

def root_mean_square(input, tsize = 150):
  root = rms(y = input *1.0)
  root = root[:, 0:min(tsize, root.shape[1])]
  root = np.pad(root, ((0,0),(0,tsize - root.shape[1])))
  output = np.ravel(root)
  return output

"""#### **Zero-Crossing Rate (ZCR)**"""

def zcr (input, tsize = 150):
  zero = zero_crossing_rate(y = input *1.0)
  zero = zero[:, 0:min(tsize, zero.shape[1])]
  zero = np.pad(zero, ((0,0),(0,tsize - zero.shape[1])))
  output = np.ravel(zero)
  return output

"""#### **Chroma**"""

def chroma(input, rate, tsize = 150):
  chroma = chroma_stft(y = input *1.0, sr=rate)
  chroma = chroma[:, 0:min(tsize, chroma.shape[1])]
  chroma = np.pad(chroma, ((0,0),(0,tsize - chroma.shape[1])))
  output = np.ravel(chroma)
  return output

"""#### **Mel Spectrogram**"""

def feats_mel(input, rate, tsize=150):
    mel_spec = melspectrogram(y=input*1.0, sr=rate)
    mel_spec = mel_spec[:, 0:min(tsize, mel_spec.shape[1])]
    mel_spec = np.pad(mel_spec, ((0,0),(0,tsize - mel_spec.shape[1])), 'constant', constant_values=(0))
    output = np.ravel(mel_spec)
    return output

"""#### **Cepstral Features (MFCC)**"""

def feats_mfcc(input, rate, tsize=150):
    mfccs = mfcc(y=input*1.0, sr=rate, n_mfcc = 40)
    mfccs = mfccs[:, 0:min(tsize, mfccs.shape[1])]
    mfccs = np.pad(mfccs, ((0,0),(0,tsize - mfccs.shape[1])), 'constant', constant_values=(0))
    output = np.ravel(mfccs)
    return output

def combo(input, rate):
    return np.concatenate((root_mean_square(input),
                           zcr(input),
                           chroma(input, rate=rate),
                           feats_mel(input, rate = rate),
                           feats_mfcc(input, rate = rate)))

X_train, X_test, y_train, y_test = load_data_csv(feature_extractor=combo, normalize=True)

# Convert everything into numpy arrays for subsequent neural processing
X_train = np.array(X_train)
y_train = np.array(y_train)
X_test = np.array(X_test)
y_test = np.array(y_test)

print(X_train.shape)
print(X_test[0].mean())
print(X_test[0].var())

#Save features
np.save('/content/gdrive/MyDrive/DSIM_Project_Monochannelsignal/extracted_features_X_train.npy', X_train)
np.save('/content/gdrive/MyDrive/DSIM_Project_Monochannelsignal/extracted_features_y_train.npy', y_train)
np.save('/content/gdrive/MyDrive/DSIM_Project_Monochannelsignal/extracted_features_X_test.npy', X_test)
np.save('/content/gdrive/MyDrive/DSIM_Project_Monochannelsignal/extracted_features_y_test.npy', y_test)

